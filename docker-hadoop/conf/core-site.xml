<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://linux121:9000</value>
    </property>


    <!-- 指定Hadoop运行时产生文件的存储目录 -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/hoult/servers/hadoop-2.9.2/data/tmp</value>
    </property>

    <!-- HiveServer2 连不上10000;hadoop为安装用户 --> <!-- root用户可以代理所有主机上的所有用户 -->
    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hadoop.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.hadoop.groups</name>
        <value>*</value>
    </property>
<!--    <property>-->
<!--        <name>fs.trash.interval</name>-->
<!--        <value>3600</value>-->
<!--    </property>-->
<!--    -->
<!--    <property>-->
<!--      <name>ha.failover-controller.active-standby-elector.zk.op.retries</name>-->
<!--      <value>120</value>-->
<!--    </property>-->
<!--    -->
<!--    <property>-->
<!--      <name>ha.zookeeper.quorum</name>-->
<!--      <value>zk1:2181,zk2:2181,zk3:2181,zk4:2181,zk5:2181</value>-->
<!--    </property>-->
<!--    -->
<!--    <property>-->
<!--      <name>hadoop.http.authentication.simple.anonymous.allowed</name>-->
<!--      <value>true</value>-->
<!--    </property>-->
</configuration>
